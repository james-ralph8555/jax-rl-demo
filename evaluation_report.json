{
  "evaluation_summary": {
    "total_episodes": 10,
    "mean_reward": 1430.4,
    "std_reward": 870.1650648009262,
    "success_rate": 0.7,
    "converged": true
  },
  "detailed_metrics": {
    "reward_statistics": {
      "mean": 1430.4,
      "std": 870.1650648009262,
      "min": 84.0,
      "max": 2000.0,
      "median": 2000.0
    },
    "length_statistics": {
      "mean": 1430.4,
      "std": 870.1650648009262,
      "min": 84.0,
      "max": 2000.0
    }
  },
  "episode_data": {
    "rewards": [
      133.0,
      84.0,
      87.0,
      2000.0,
      2000.0,
      2000.0,
      2000.0,
      2000.0,
      2000.0,
      2000.0
    ],
    "lengths": [
      133,
      84,
      87,
      2000,
      2000,
      2000,
      2000,
      2000,
      2000,
      2000
    ]
  }
}